{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-22T13:40:41.554594",
     "start_time": "2016-07-22T13:40:41.548978"
    }
   },
   "source": [
    "# Initialize the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-08T10:09:34.239082",
     "start_time": "2016-09-08T10:09:33.944516"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    \n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import subprocess\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import fig_plotting\n",
    "rcParams = fig_plotting.update_rcparams(rcParams)\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "os.chdir('../')\n",
    "import Codebase\n",
    "conv_adj_matr_to_cfg_matr = Codebase.Networks.configuration.convert_adj_matr_to_cfg_matr\n",
    "conv_cfg_vec_to_adj_matr = Codebase.Networks.configuration.convert_conn_vec_to_adj_matr\n",
    "from Codebase.Networks.SubgraphDetection.nonnegfac import nmf\n",
    "os.chdir('./Analysis_Notebooks/')\n",
    "\n",
    "path_MetaData = '/home1/a/ankk/LittHome/Remotes/CORE.ieeg_ltm.multiinst/Raw_Neocortical'\n",
    "path_CoreData = '/home1/a/ankk/LittHome/Remotes/CORE.ieeg_ltm.multiinst/Dyne_Neocortical/FuncConn.XCorr_WideBand.4_115/network'\n",
    "path_PeriphData = '/home1/a/ankk/LittHome/Remotes/RSRCH.InterictalSubgraph'\n",
    "path_InpData_Opt = path_PeriphData + '/ds-e01-NMF_Optimization'\n",
    "path_InpData_Est = path_PeriphData + '/ds-e02-NMF_Estimation'\n",
    "path_ExpData = path_PeriphData + '/ds-e03-NMF_Consensus'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generate Data List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-08T10:09:50.886707",
     "start_time": "2016-09-08T10:09:50.249529"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get clinical_metadata\n",
    "df_meta = h5py.File('{}/clinical_metadata.mat'.format(path_MetaData), 'r')\n",
    "meta_subj = [''.join(unichr(c) for c in df_meta[r])\n",
    "             for r in df_meta['subject']['ID'][:, 0]]\n",
    "\n",
    "# Read the Condition Checking Result\n",
    "ev_list = np.load(\"{}/NMF_Good_Events.npz\".format(path_InpData_Opt))['event_list']\n",
    "\n",
    "subj_dict = {}\n",
    "good_ev_list = []\n",
    "bad_ev_list = []\n",
    "for path, cnd_num in ev_list:\n",
    "    path = str(path)\n",
    "    cnd_num = float(cnd_num)\n",
    "    \n",
    "    if np.isnan(cnd_num) or (cnd_num > 1e5):\n",
    "        bad_ev_list.append(path)\n",
    "        continue\n",
    "    else:\n",
    "        good_ev_list.append(path)\n",
    "\n",
    "    full_id = path.split('/')[-1]\n",
    "    subj_id = full_id.split('-')[0]\n",
    "    epoch_id = full_id.split('-')[1]\n",
    "    block_id = full_id.split('-')[3].split('.')[0]\n",
    "    \n",
    "    try:\n",
    "        subj_dict[subj_id]\n",
    "    except KeyError:\n",
    "        subj_dict[subj_id] = {}\n",
    "\n",
    "    try:\n",
    "        subj_dict[subj_id][epoch_id]\n",
    "    except KeyError:\n",
    "        subj_dict[subj_id][epoch_id] = {}\n",
    "\n",
    "    # Check that the path exists\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        subj_dict[subj_id][epoch_id][block_id]\n",
    "    except KeyError:\n",
    "        subj_dict[subj_id][epoch_id][block_id] = {}\n",
    "    \n",
    "    subj_dict[subj_id][epoch_id][block_id] = \\\n",
    "               {'dyne_output': path,\n",
    "                'dyne_log': '{}/{}-{}-block-{}.mat.dyne_log.csv'.format(path_CoreData,\n",
    "                                                                        subj_id, epoch_id, block_id)\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF Subgraph Consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-22T14:28:35.281971",
     "start_time": "2016-07-22T14:28:32.439165"
    }
   },
   "source": [
    "## Set processing items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-08T10:10:08.554348",
     "start_time": "2016-09-08T10:10:07.584925"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proc_item = []\n",
    "for subj_id in subj_dict.keys():\n",
    "\n",
    "    for path in glob.glob('{}/{}.*.npz'.format(path_InpData_Est, subj_id)):\n",
    "        epoch_id = path.split('/')[-1].split('.')[1]\n",
    "        block_id = path.split('/')[-1].split('.')[2]\n",
    "\n",
    "        proc_dict = {'estimate_path': path,\n",
    "                     'data_path': subj_dict[subj_id][epoch_id][block_id],\n",
    "                     'output_name': '{}.{}.{}'.format(subj_id, epoch_id, block_id)}\n",
    "        proc_item.append(proc_dict)\n",
    "        \n",
    "np.savez('{}/NMF_Consensus.Proc_Items.npz'.format(path_ExpData),\n",
    "         proc_item=proc_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-22T15:09:21.277007",
     "start_time": "2016-07-22T15:09:20.919354"
    }
   },
   "source": [
    "## Run NMF on Proc_Item List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-08T12:27:26.013160",
     "start_time": "2016-09-08T12:27:08.475494"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: MAYO026.interictal.794\n",
      "Processing: MAYO031.interictal.314\n",
      "Processing: HUP86.interictal.53\n",
      "Processing: HUP65.interictal.2579\n",
      "Processing: HUP87.interictal.107\n",
      "Processing: MAYO019.interictal.951\n",
      "Processing: HUP64.interictal.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:55: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:55: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:290: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:290: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:55: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:290: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:55: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:290: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:55: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:290: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:55: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:290: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:55: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "Codebase/Networks/SubgraphDetection/nonnegfac/nnls.py:290: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "parallel_run = True\n",
    "\n",
    "proc_item = np.load('{}/NMF_Consensus.Proc_Items.npz'.format(path_ExpData))['proc_item']\n",
    "\n",
    "# Remove already completed items from proc list\n",
    "new_proc_item = []\n",
    "for pitem in proc_item:\n",
    "    if not os.path.exists(\"{}/{}.npz\".format(path_ExpData, pitem['output_name'])):\n",
    "        new_proc_item.append(pitem)\n",
    "proc_item = new_proc_item\n",
    "\n",
    "# Setup helper function to map NMF run\n",
    "def _start_helper(pitem):\n",
    "    print('Processing: {}'.format(pitem['output_name']))\n",
    "    \n",
    "    # Getting Data from Dyne\n",
    "    df_log = pd.read_csv(pitem['data_path']['dyne_log'], delimiter=',')\n",
    "    pipe_hash = np.array(df_log[df_log.PIPE_NAME == 'CrossCorrelation'].DOWNSTREAM_HASH)[0]\n",
    "    df_outp = h5py.File(pitem['data_path']['dyne_output'], 'r')\n",
    "    cfg_matr = conv_adj_matr_to_cfg_matr(df_outp[pipe_hash]['data'][...])\n",
    "    \n",
    "    # Setup NMF\n",
    "    df_est = np.load(pitem['estimate_path'])\n",
    "    n_est = len(df_est['subgraph_estimate'])\n",
    "    n_fac = df_est['subgraph_estimate'][0]['fac_subnet'].shape[0]\n",
    "    n_conn = df_est['subgraph_estimate'][0]['fac_subnet'].shape[1]\n",
    "    n_win = df_est['subgraph_estimate'][0]['fac_coef'].shape[1]\n",
    "\n",
    "    # fac subnet\n",
    "    fac_subnet_est = np.array([subnet\n",
    "                               for subg_est in df_est['subgraph_estimate']\n",
    "                               for subnet in subg_est['fac_subnet']])\n",
    "    n_obs = fac_subnet_est.shape[0]\n",
    "    \n",
    "    try:\n",
    "        # Consensus Subgraphs\n",
    "        fac_subnet_cons, _, err = nmf.snmf_bcd(\n",
    "            fac_subnet_est,\n",
    "            alpha=0.0,\n",
    "            beta=0.0,\n",
    "            fac_subnet_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_conn)),\n",
    "            fac_coef_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_obs)),\n",
    "            max_iter=100, verbose=False)\n",
    "\n",
    "        # Consensus Coefficients\n",
    "        fac_subnet_cons_2, fac_coef_cons_2, err = nmf.snmf_bcd(\n",
    "            cfg_matr,\n",
    "            alpha=0.0,\n",
    "            beta=0.0,\n",
    "            fac_subnet_init=fac_subnet_cons,\n",
    "            fac_coef_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_win)),\n",
    "            max_iter=100, verbose=False)\n",
    "    except:\n",
    "        return 0\n",
    "            \n",
    "    # Cache the NMF result\n",
    "    np.savez(\"{}/{}.npz\".format(path_ExpData, pitem['output_name']),\n",
    "             fac_subnet=fac_subnet_cons_2, fac_coef=fac_coef_cons_2, err=err)\n",
    "    \n",
    "if parallel_run:\n",
    "    mp = Pool(30)\n",
    "    mp.map(_start_helper, proc_item)\n",
    "else:\n",
    "    map(_start_helper, proc_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-08T12:27:57.125783",
     "start_time": "2016-09-08T12:27:56.667183"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home1/a/ankk/LittHome/Remotes/RSRCH.InterictalSubgraph/ds-e03-NMF_Consensus/HUP78.interictal.2788.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d4eb0021ec41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}.npz\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_ExpData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HUP78.interictal.2788'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfac_subnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fac_subnet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfac_coef_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fac_coef'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/a/ankk/Developer/miniconda2/envs/cb-resection/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home1/a/ankk/LittHome/Remotes/RSRCH.InterictalSubgraph/ds-e03-NMF_Consensus/HUP78.interictal.2788.npz'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df_out = np.load(\"{}/{}.npz\".format(path_ExpData, 'HUP65.interictal.2579'))\n",
    "fac_subnet = df_out['fac_subnet'][2, :]\n",
    "fac_coef_all = df_out['fac_coef']\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "ax = plt.subplot(1,2,1)\n",
    "ax.matshow(conv_cfg_vec_to_adj_matr(fac_subnet), cmap='rainbow')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "for ii in xrange(fac_coef_all.shape[0]):\n",
    "    fac_coef = fac_coef_all[ii, :]\n",
    "    fac_coef = (fac_coef - fac_coef.mean()) / (3*fac_coef.std())\n",
    "    ax.plot(np.arange(len(fac_coef)),\n",
    "            fac_coef+ii)\n",
    "ax.set_ylim([-1, ii+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
